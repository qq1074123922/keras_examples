{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 独立实现情感分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. 数据准备\n",
    "2. 建立模型，编译\n",
    "3. 训练模型\n",
    "4. 进行评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "等会将数据储存在csv中拷贝过来"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型，双编码长短记忆模型，只使用一个LSTM层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.models\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res=np.load('imdb.npz')\n",
    "#将训练数据和测试数据加载进来\n",
    "x_train=res['x_train']\n",
    "y_train=res['y_train']\n",
    "x_test=res['x_test']\n",
    "y_test=res['y_test']\n",
    "#将数据分好\n",
    "res.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要统计出最大的一个index，然后加1，作为嵌入层的参数\n",
    "vocab_sizes=np.max([np.max(x) for x in x_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88585"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_sizes=vocab_sizes+1\n",
    "vocab_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 在使用深度学习进行文本相关的分析的时候，需要记住文本预处理的相关步骤：\n",
    "1. 文本常规的预处理，清洗文本\n",
    "2. 然后每一个文档转化成一个向量，这里有两种方式：\n",
    "    * 一种是直接使用word2vec对每个文档进行向量化\n",
    "    * 另外一种是直接使用keras中的嵌入层实现文档向量化\n",
    "    \n",
    "    \n",
    "    \n",
    "在使用keras中的嵌入层进行词嵌入操作前需要进行如下几个操作：\n",
    "1.文字拆分\n",
    "2.建立索引\n",
    "3.序列补齐（padding）\n",
    "4.转换为矩阵\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#进行序列补齐和转换为矩阵，\n",
    "#这个训练文档已经是一个矩阵，但是该矩阵的长度不一样，所以需要将长度限定一下，全部限定在300个长度\n",
    "from keras.preprocessing import sequence\n",
    "x_train_pad=sequence.pad_sequences(sequences=x_train,maxlen=400)\n",
    "x_test_pad=sequence.pad_sequences(sequences=x_test,maxlen=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 400)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#开始建立一个LSTM模型，首先需要确定使用的是序列模型，还是函数式模型\n",
    "#这里准备使用序列模型\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import SGD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#如何确定嵌入层的参数，\n",
    "#嵌入层的功能是？参数有什么？，词典最大index，输入的个数，输出的维度。\n",
    "#嵌入层的功能是：将所有的索引号映射到一个致密的低维向量中，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88585"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 400, 300)          26575500  \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 400, 200)          400800    \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 32)                29824     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 27,006,157\n",
      "Trainable params: 27,006,157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(input_dim=vocab_sizes,output_dim=300,input_length=400))#添加一个嵌入层，对词进行向量化，\n",
    "\n",
    "model.add(LSTM(200,return_sequences=True,dropout=0.2,kernel_initializer='random_normal'))#添加lstm层\n",
    "model.add(LSTM(units=32,dropout=0.2))\n",
    "model.add(Dense(activation='sigmoid',units=1))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd=SGD(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 3143s - loss: 0.4781 - acc: 0.7812 - val_loss: 0.3381 - val_acc: 0.8610\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 3039s - loss: 0.2842 - acc: 0.8884 - val_loss: 0.3549 - val_acc: 0.8729\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 3006s - loss: 0.2067 - acc: 0.9258 - val_loss: 0.3675 - val_acc: 0.8713\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 2883s - loss: 0.1462 - acc: 0.9478 - val_loss: 0.4013 - val_acc: 0.8606\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 3008s - loss: 0.1077 - acc: 0.9632 - val_loss: 0.3971 - val_acc: 0.8668\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 2969s - loss: 0.0817 - acc: 0.9712 - val_loss: 0.6942 - val_acc: 0.8147\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 3028s - loss: 0.0646 - acc: 0.9784 - val_loss: 0.4626 - val_acc: 0.8585\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 3231s - loss: 0.0498 - acc: 0.9841 - val_loss: 0.5030 - val_acc: 0.8543\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 3719s - loss: 0.0372 - acc: 0.9886 - val_loss: 0.5437 - val_acc: 0.8565\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 3654s - loss: 0.0300 - acc: 0.9914 - val_loss: 0.6430 - val_acc: 0.8447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x221e19e8>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(epochs=10,x=x_train_pad,y=y_train,batch_size=100,validation_data=(x_test_pad,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 821s   \n",
      "[0.6916507942461968, 0.84743999999999997]\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test_pad, y_test)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "85px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
